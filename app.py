import streamlit as st
import google.generativeai as genai
from pinecone import Pinecone
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="Regista Tactical Hub", page_icon="âš½", layout="wide")

# --- CSS Ä°LE GÃ–RSELLÄ°K ---
st.markdown("""
<style>
    .main {background-color: #0e1117;}
    h1 {color: #ff4b4b;}
    .stChatMessage {border-radius: 10px;}
</style>
""", unsafe_allow_html=True)

# --- BAÅLIK ---
st.title("âš½ Regista Tactical Hub")
st.caption("AI Destekli Taktik Analiz & ArÅŸiv UzmanÄ±")

# --- API KURULUMLARI ---
# Sadece Google ve Pinecone kontrolÃ¼ yapÄ±yoruz (Firebase YOK)
if "GOOGLE_API_KEY" in st.secrets and "PINECONE_API_KEY" in st.secrets:
    # 1. Google Gemini Kurulumu
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    
    # 2. Pinecone BaÄŸlantÄ±sÄ± (ArÅŸiv iÃ§in)
    try:
        pc = Pinecone(api_key=st.secrets["PINECONE_API_KEY"])
        index_name = "regista-arsiv"
        pinecone_index = pc.Index(index_name)
        
        # Embedding modeli
        embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001", 
            google_api_key=st.secrets["GOOGLE_API_KEY"]
        )
        db_status = "ğŸŸ¢ ArÅŸiv BaÄŸlÄ±"
    except Exception as e:
        pinecone_index = None
        db_status = f"ğŸ”´ ArÅŸiv HatasÄ±: {e}"
        # Hata olsa bile devam et, en azÄ±ndan sohbet Ã§alÄ±ÅŸsÄ±n

else:
    st.error("ğŸš¨ HATA: API AnahtarlarÄ± Eksik! LÃ¼tfen Streamlit Secrets ayarlarÄ±nÄ± kontrol et.")
    st.info("Gerekli Anahtarlar: GOOGLE_API_KEY, PINECONE_API_KEY")
    st.stop()

# --- YAN MENÃœ ---
with st.sidebar:
    st.header("Saha KenarÄ±")
    st.info(f"VeritabanÄ± Durumu: {db_status}")
    st.markdown("---")
    st.markdown("**NasÄ±l KullanÄ±lÄ±r?**")
    st.markdown("1. Sorunu yaz (Ã–rn: 'Gegenpressing nedir?')")
    st.markdown("2. AI hem bilgisiyle hem de **Bundesliga arÅŸivinden** tarayarak cevaplar.")

# --- SOHBET GEÃ‡MÄ°ÅÄ° ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Merhaba Hocam! Sahaya hoÅŸ geldin. ArÅŸivdeki maÃ§ analizleri emrine amade. Ne analiz edelim?"}
    ]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- FONKSÄ°YON: ArÅŸivden Bilgi Ã‡ek (RAG) ---
def arsivden_bul(soru):
    if not pinecone_index:
        return None, []
    
    try:
        # 1. Soruyu vektÃ¶re Ã§evir
        soru_vektor = embeddings.embed_query(soru)
        
        # 2. Pinecone'da en benzer 3 dÃ¶kÃ¼manÄ± bul
        sonuc = pinecone_index.query(
            vector=soru_vektor,
            top_k=3,
            include_metadata=True
        )
        
        # 3. Metinleri birleÅŸtir
        bulunan_bilgiler = ""
        kaynaklar = []
        for match in sonuc['matches']:
            if 'text' in match['metadata']:
                bulunan_bilgiler += match['metadata']['text'] + "\n\n"
                # Kaynak ismini dÃ¼zeltelim (source yoksa text'ten kÄ±rp)
                src = match['metadata'].get('source', 'Bilinmeyen Dosya')
                kaynaklar.append(src)
        
        return bulunan_bilgiler, list(set(kaynaklar))
    except Exception as e:
        print(f"Arama HatasÄ±: {e}")
        return None, []

# --- SOHBET MANTIÄI ---
if prompt := st.chat_input("Taktiksel sorunu sor..."):
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Asistan cevabÄ± hazÄ±rlanÄ±yor
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ğŸ” *ArÅŸiv taranÄ±yor...*")
        
        # 1. Ã–nce ArÅŸivden Bilgi Getir
        context_text, kaynaklar = arsivden_bul(prompt)
        
        # 2. Gemini'ye Prompt HazÄ±rla
        base_prompt = """
        Sen 'Regista AI' adÄ±nda uzman bir futbol analistisin.
        Sana kullanÄ±cÄ±nÄ±n Ã¶zel arÅŸivinden bulduÄŸumuz metinler verildi.
        
        Kurallar:
        1. Ã–ncelikle 'BULUNAN ARÅÄ°V BÄ°LGÄ°LERÄ°'ni kullan.
        2. ArÅŸivde bilgi yoksa, kendi bilgini kullan ama bunu belirt.
        3. Profesyonel, taktiksel konuÅŸ.
        """
        
        if context_text:
            final_prompt = f"{base_prompt}\n\nKULLANICI SORUSU: {prompt}\n\nBULUNAN ARÅÄ°V BÄ°LGÄ°LERÄ°:\n{context_text}"
        else:
            final_prompt = f"{base_prompt}\n\nKULLANICI SORUSU: {prompt}\n\n(ArÅŸivde bilgi bulunamadÄ±, genel bilgi ver.)"

        # 3. Modele Sor
        try:
            # Model ismini deÄŸiÅŸtirebilirsin (gemini-2.0-flash-exp veya gemini-1.5-flash)
            model = genai.GenerativeModel('gemini-2.5-flash') 
            response = model.generate_content(final_prompt)
            ai_response = response.text
            
            # KaynaklarÄ± ekle
            if kaynaklar:
                kaynak_notu = "\n\n--- \nğŸ“š **Kaynaklar:**\n" + "\n".join([f"- {k}" for k in kaynaklar])
                ai_response += kaynak_notu
            
            message_placeholder.markdown(ai_response)
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
            
        except Exception as e:
            st.error(f"Bir hata oluÅŸtu: {e}")
